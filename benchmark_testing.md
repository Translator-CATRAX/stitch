# `normalize_kg2pre.py` Benchmark Testing
Trial Name | Commit | Start Time | End Time | Run Time | Peak Memory Usage | Size (bytes) | Notes
--|--|--|--|--|--|--|--
Base Trial | [`3a7bf70`](https://github.com/Translator-CATRAX/stitch/commit/3a7bf70f0dafbc7c955196e6cb30b2f8bfce604d) | `Sun Aug  3 05:07:07 UTC 2025` | `Sun Aug  3 10:25:24 UTC 2025` | 5 hours, 18 minutes, 17 seconds | 31% (on `r5a.4xlarge`) | 14958920 | The memory tracker was started about 1 hour and 9 minutes into the build.
JSONLines Streaming System | [`7f70612`](https://github.com/Translator-CATRAX/stitch/commit/7f7061204234bab174d19f68a129d32a479a7996) | `Mon Aug  4 23:45:24 UTC 2025` | `Tue Aug  5 02:59:38 UTC 2025` | 3 hours, 14 minutes, 14 seconds | 2% (on `r5a.4xlarge`) | 14959840 | This wasn't run on a fresh instance. (Base Trial had already been run; this test was also started but abandoned about 40 minutes into the build after I realized I forgot to measure memory usage. I am unclear whether this would have impacted the indices.) The script used was `normalize_kg2pre_jsonlines.py`. Additionally, I can't run a direct comparison on content because the Base Trial had unsorted keys while this trial had sorted keys in the JSONLines file. I am unclear why this file is 80 bytes smaller. It does not seem to be a systemic error or I would expect the difference to be significantly larger.
`issue-40` Optimizations | [`b03785f`](https://github.com/Translator-CATRAX/stitch/commit/b03785faf19f0fd0a86568a32826e69b8c222557) | `Tue Aug  5 03:44:06 UTC 2025` | `Tue Aug  5 07:11:41 UTC 2025` | 3 hours, 27 minutes, 35 seconds | 2% (on `r5a.4xlarge`) | 14831612 | I am very surprised by this result. Steve estimated that these optimizations produce a script that took under 30 minutes. However, this was run on the same hardware and the same Babel SQLite file as the previous two tests. The processing after the initial progress bar took, in particular, far longer than I expected (I would estimate roughly 1 hour). While these optimizations do improve on the base trial, they ultimately do not improve on the results of the JSONLines streaming system (which was developed independently of these optimizations - the two are not immediately compatible).
`issue-40-2` Naive Parallelism | [`c0c7d73`](https://github.com/Translator-CATRAX/stitch/commit/c0c7d730311da97ba2ab69ce9d78715bb5d2a615) | `Tue Aug  5 08:27:10 UTC 2025` | `Tue Aug  5 09:01:54 UTC 2025` | 34 minutes, 44 seconds | 3% (on `r5a.4xlarge`) | 14958924 | This implementation simply split the edges file into 16 separate files and called the `normalize_kg2pre_jsonlines.py` script on each of them, in paralle, before merging the outputs. While not perfect linear scaling, this drastically reduced the processing time. Surprisingly, this didn't increase memory usage much. Thus, this seems ideal for incorporating into the KG2 build, once all of the other requirements are met. While this is not as elegant as using `multiprocessing` in Python, this is evidently much easier, since a significant burden is loading the JSON Lines edges file while maintaining streaming capabilities.
`issue-40` Multiprocessing | [`1605b7b`](https://github.com/Translator-CATRAX/stitch/commit/1605b7baf3594895f388290fff07428e9a9fb3e4) | `Wed Aug  6 06:23:07 UTC 2025` | `Wed Aug  6 07:36:28 UTC 2025` | 1 hour, 13 minutes, 21 seconds | 6% (on `r5a.4xlarge`) | 14959304 | In Steve's test, this only took 24 minutes. I am investigating to see if this is an issue with SQLite caching.
`issue-40` Multiprocessing Build 2| [`1605b7b`](https://github.com/Translator-CATRAX/stitch/commit/1605b7baf3594895f388290fff07428e9a9fb3e4) | `Wed Aug  6 07:39:25 UTC 2025` | `Wed Aug  6 08:51:37 UTC 2025` | 1 hour, 12 minutes, 14 seconds | 19% (on `r5a.4xlarge`) | 14958388 | This was run to investigate whether caching was responsible for the large gap between the naive parallelism performance and the multiprocessing performance. It did not meaningfully improve performance. Further, the output file is of a slightly different size which is concerning. The only change in the code was to change the output filename (to preserve the old file). Additionally, the memory usage peaked much higher. Currently, I am not sure why this gap occurred. More investigation is required.
`issue-40` Multiprocessing `i4i.2xlarge`| [`1605b7b`](https://github.com/Translator-CATRAX/stitch/commit/1605b7baf3594895f388290fff07428e9a9fb3e4) | `Wed Aug  6 18:32:22 UTC 2025` | `Wed Aug  6 19:14:58 UTC 2025` | 42 minutes, 36 seconds | 8\% (on `i4i.2xlarge`) | 15318233139 | 
